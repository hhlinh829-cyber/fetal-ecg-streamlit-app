import streamlit as st
import pandas as pd
import numpy as np
import joblib
import os 

# C·∫§U H√åNH TRANG WEB
st.set_page_config(page_title="Ch·∫©n ƒëo√°n CTG AI", layout="wide")

# ==============================================================================
# PH·∫¶N 1: T·∫¢I M√î H√åNH V√Ä SCALER (ƒê√É S·ª¨A L·ªñI T·∫¢I FILE)
# ==============================================================================

@st.cache_resource
def load_model_and_scaler():
    """T·∫£i m√¥ h√¨nh v√† scaler ƒë√£ l∆∞u."""
    model_path = 'fetal_health_model.pkl'
    scaler_path = 'fetal_health_scaler.pkl'
    
    # Ki·ªÉm tra s·ª± t·ªìn t·∫°i c·ªßa t·ªáp
    if not os.path.exists(model_path) or not os.path.exists(scaler_path):
        st.error("L·ªói T·∫£i File: Kh√¥ng t√¨m th·∫•y file m√¥ h√¨nh ho·∫∑c scaler. Vui l√≤ng ki·ªÉm tra t√™n file tr√™n GitHub.")
        return None, None
    
    try:
        model = joblib.load(model_path)
        scaler = joblib.load(scaler_path)
        # st.success("T·∫£i m√¥ h√¨nh th√†nh c√¥ng! ·ª®ng d·ª•ng ƒë√£ s·∫µn s√†ng.") 
        return model, scaler
    except Exception as e:
        st.error(f"L·ªói: Kh√¥ng th·ªÉ ƒë·ªçc file m√¥ h√¨nh. Chi ti·∫øt l·ªói: {e}")
        return None, None

# G·ªçi h√†m t·∫£i m√¥ h√¨nh v√† scaler
model, scaler = load_model_and_scaler()

# D·ª´ng ·ª©ng d·ª•ng n·∫øu m√¥ h√¨nh kh√¥ng t·∫£i ƒë∆∞·ª£c
if model is None or scaler is None:
    st.stop()
    
# ==============================================================================
# PH·∫¶N 2: GIAO DI·ªÜN V√Ä X·ª¨ L√ù D·ªÆ LI·ªÜU (PH·∫¶N B·ªä THI·∫æU)
# ==============================================================================

st.title("ü©∫ ·ª®ng D·ª•ng Ph√¢n T√≠ch ƒêi·ªán Tim Thai (CTG) - Ch·∫©n ƒëo√°n S∆° b·ªô AI")
st.markdown("---")
st.subheader("Nh·∫≠p 21 Ch·ªâ S·ªë ƒêi·ªán Tim Thai (CTG)")

# T√™n c√°c c·ªôt ƒë·∫ßu v√†o (d√πng ƒë·ªÉ hi·ªÉn th·ªã)
FEATURE_NAMES = [
    'baseline value (bpm)', 'accelerations (per sec)', 'fetal_movement (per sec)',
    'uterine_contractions (per sec)', 'light_decelerations (per sec)', 
    'severe_decelerations (per sec)', 'prolongued_decelerations (per sec)',
    'abnormal_short_term_variability (%)', 'mean_value_of_short_term_variability',
    'percentage_of_time_with_abnormal_long_term_variability (%)', 
    'mean_value_of_long_term_variability', 'histogram_width', 'histogram_min',
    'histogram_max', 'histogram_number_of_peaks', 'histogram_number_of_zeroes',
    'histogram_mode', 'histogram_mean', 'histogram_median', 'histogram_variance',
    'histogram_tendency'
]

# Gi√° tr·ªã m·∫∑c ƒë·ªãnh cho 21 ch·ªâ s·ªë (v√≠ d·ª• t·ª´ d·ªØ li·ªáu b√¨nh th∆∞·ªùng)
DEFAULT_VALUES = [
    120.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 73.0, 0.5, 43.0, 2.4, 64.0, 62.0, 
    126.0, 2.0, 0.0, 120.0, 137.0, 121.0, 73.0, 1.0
]


# Chia giao di·ªán th√†nh 3 c·ªôt ƒë·ªÉ nh·∫≠p li·ªáu
input_data = {}
cols = st.columns(3)

for i, feature in enumerate(FEATURE_NAMES):
    col_index = i % 3
    with cols[col_index]:
        # T·∫°o √¥ nh·∫≠p li·ªáu cho t·ª´ng t√≠nh nƒÉng
        # S·ª≠ d·ª•ng format="%.4f" cho c√°c gi√° tr·ªã nh·ªè, v√† format="%d" cho c√°c gi√° tr·ªã l·ªõn
        
        # Ch·ªâ s·ªë 0-6 l√† c√°c t·∫ßn su·∫•t (d√πng 4 ch·ªØ s·ªë th·∫≠p ph√¢n)
        if i <= 6:
            input_data[feature] = st.number_input(f"Nh·∫≠p **{feature}**", 
                                                value=DEFAULT_VALUES[i], 
                                                step=0.0001, 
                                                format="%.4f",
                                                key=f"input_{i}")
        # Ch·ªâ s·ªë 7-20 l√† c√°c gi√° tr·ªã l·ªõn h∆°n (d√πng 2 ch·ªØ s·ªë th·∫≠p ph√¢n ho·∫∑c s·ªë nguy√™n)
        else:
            input_data[feature] = st.number_input(f"Nh·∫≠p **{feature}**", 
                                                value=DEFAULT_VALUES[i], 
                                                step=0.1, 
                                                format="%.2f",
                                                key=f"input_{i}")


# N√öT D·ª∞ ƒêO√ÅN
st.markdown("---")
st.subheader("B·∫•m v√†o ƒë·ªÉ xem k·∫øt qu·∫£ ch·∫©n ƒëo√°n s∆° b·ªô")

if st.button('üîÆ Ch·∫©n ƒêo√°n S∆° B·ªô', use_container_width=True):
    
    # Chu·∫©n b·ªã d·ªØ li·ªáu ƒë·∫ßu v√†o
    input_df = pd.DataFrame([input_data])
    
    # Chu·∫©n h√≥a d·ªØ li·ªáu (Scaling)
    # L∆∞u √Ω: fit_transform ch·ªâ d√πng khi training. ·ªû ƒë√¢y ta d√πng transform.
    scaled_data = scaler.transform(input_df)
    
    # D·ª± ƒëo√°n
    prediction = model.predict(scaled_data)
    
    # Gi·∫£i m√£ k·∫øt qu·∫£
    # 1: Normal (B√¨nh th∆∞·ªùng), 2: Suspect (Nghi ng·ªù), 3: Pathologic (B·ªánh l√Ω)
    if prediction[0] == 1:
        result = "B√¨nh th∆∞·ªùng (Normal) ‚úÖ"
        st.success(f"K·∫øt Qu·∫£ Ph√¢n T√≠ch AI: {result}")
    elif prediction[0] == 2:
        result = "Nghi ng·ªù (Suspect) ‚ö†Ô∏è"
        st.warning(f"K·∫øt Qu·∫£ Ph√¢n T√≠ch AI: {result}")
    else:
        result = "B·ªánh l√Ω (Pathologic) üî¥"
        st.error(f"K·∫øt Qu·∫£ Ph√¢n T√≠ch AI: {result}")
        
    st.balloons()
